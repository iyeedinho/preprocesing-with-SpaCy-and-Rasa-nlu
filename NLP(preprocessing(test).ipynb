{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP(preprocessing(test).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "159m-ngMTj3HQDWoG5FG7jZkLYGMMWsQ7",
      "authorship_tag": "ABX9TyMqqG0rvoakdCurlE6ty1W/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyeedinho/preprocesing-with-spacy/blob/master/NLP(preprocessing(test).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y30fQxH4jmX-",
        "colab_type": "text"
      },
      "source": [
        "# Installing the library SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8-a6ai8Yc1P",
        "colab_type": "code",
        "outputId": "bc94d362-5542-48c9-ef46-a1eaef4c348d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! sudo pip install spacy\n",
        "! sudo python -m spacy download en\n",
        "! sudo python -m spacy download fr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting fr_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 810kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=953129e9ef44aee0e9e3191d52496c4a7a680c7bc332f07ab1832672eda4e5df\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wdhdsx57/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIfcQAnylK2l",
        "colab_type": "text"
      },
      "source": [
        "# Loading the package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4rJVdK-Y1jL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oScUcJM5mTpG",
        "colab_type": "text"
      },
      "source": [
        "# Reading a document or text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5A1Wp6GmbQr",
        "colab_type": "code",
        "outputId": "b2437034-2c78-4f89-f90a-37aa16420318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "docx=nlp(\"SpaCy is an cool tool\")\n",
        "docx\n",
        "doc_file=nlp(open(\"/content/drive/My Drive/text.txt\").read())\n",
        "doc_file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Natural Language Processing is the technology used to aid computers to understand the human’s natural language.\n",
              "It’s not an easy task teaching machines to understand how we communicate.\n",
              "Leand Romaf, an experienced software engineer who is passionate at teaching people how artificial intelligence systems work, says that “in recent years, there have been significant breakthroughs in empowering computers to understand language just as we do.”\n",
              "This article will give a simple introduction to Natural Language Processing and how it can be achieved.\n",
              "What is Natural Language Processing\n",
              "Natural Language Processing, usually shortened as NLP, is a branch of artificial intelligence that deals with the interaction between computers and humans using the natural language.\n",
              "The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n",
              "Most NLP techniques rely on machine learning to derive meaning from human languages."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdN3_uqeoVPG",
        "colab_type": "text"
      },
      "source": [
        "# Sentence Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbjzraw1oVak",
        "colab_type": "code",
        "outputId": "d4267bde-2cb9-44d7-d628-99d47302d1e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "for num,sentence in enumerate(doc_file.sents):\n",
        "  print(f'{num}:{sentence}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:Natural Language Processing is the technology used to aid computers to understand the human’s natural language.\n",
            "\n",
            "1:It’s not an easy task teaching machines to understand how we communicate.\n",
            "\n",
            "2:Leand Romaf, an experienced software engineer who is passionate at teaching people how artificial intelligence systems work, says that “in recent years, there have been significant breakthroughs in empowering computers to understand language just as we do.”\n",
            "\n",
            "3:This article will give a simple introduction to Natural Language Processing and how it can be achieved.\n",
            "\n",
            "4:What is Natural Language Processing\n",
            "Natural Language Processing, usually shortened as NLP, is a branch of artificial intelligence that deals with the interaction between computers and humans using the natural language.\n",
            "\n",
            "5:The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n",
            "\n",
            "6:Most NLP techniques rely on machine learning to derive meaning from human languages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIJVGao5thzo",
        "colab_type": "text"
      },
      "source": [
        "# Word Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1bEgY5ptiH_",
        "colab_type": "code",
        "outputId": "d30026ac-f6d5-42a9-9a09-5722dc618627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#word tokens\n",
        "for token in docx:\n",
        "  print(token.text)\n",
        "#List of word tokens\n",
        "\"[token.text for token in docx]\"\n",
        "docx.text.split(\" \")\n",
        "#Word shape\n",
        "for word in docx:\n",
        "  print(word.text,word.shape_,word.is_alpha,word.is_stop)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SpaCy\n",
            "is\n",
            "an\n",
            "cool\n",
            "tool\n",
            "SpaCy XxxXx True False\n",
            "is xx True True\n",
            "an xx True True\n",
            "cool xxxx True False\n",
            "tool xxxx True False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcSKH_fiSHZU",
        "colab_type": "text"
      },
      "source": [
        "# Speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlMOapFZSHnP",
        "colab_type": "code",
        "outputId": "7cbaa19f-cb87-4e46-c601-ac619db8e10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "#parts of speech\n",
        "exp1= nlp(\"he drinks a drink\")\n",
        "for word in exp1:\n",
        "  print(word.text,word.pos_)\n",
        "\n",
        "exp2=nlp(\"i fish a fish\")\n",
        "for word in exp2:\n",
        "  print(word.text,word.pos_,word.tag_)\n",
        "\n",
        "#spacy explanation\n",
        "spacy.explain('VBP')\n",
        "\n",
        "exp3=nlp(\"all the faith he had had had had no effect on the outcome of his life\")\n",
        "for word in exp3:\n",
        "  print ((word.text,word.tag_))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "he PRON\n",
            "drinks VERB\n",
            "a DET\n",
            "drink NOUN\n",
            "i PRON PRP\n",
            "fish VERB VBP\n",
            "a DET DT\n",
            "fish NOUN NN\n",
            "('all', 'PDT')\n",
            "('the', 'DT')\n",
            "('faith', 'NN')\n",
            "('he', 'PRP')\n",
            "('had', 'VBD')\n",
            "('had', 'VBN')\n",
            "('had', 'VBN')\n",
            "('had', 'VBN')\n",
            "('no', 'DT')\n",
            "('effect', 'NN')\n",
            "('on', 'IN')\n",
            "('the', 'DT')\n",
            "('outcome', 'NN')\n",
            "('of', 'IN')\n",
            "('his', 'PRP$')\n",
            "('life', 'NN')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPVyrQ3QVP8x",
        "colab_type": "text"
      },
      "source": [
        "# Syntactic Dependency\n",
        "\n",
        "\n",
        "> it helps us to know the relation beetween tokens\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-jwY7paVQIV",
        "colab_type": "code",
        "outputId": "627b4b5a-87c6-4275-e648-ea1441573c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "exp4=nlp(\"Sally likes sam\")\n",
        "for word in exp4:\n",
        "  print ((word.text,word.tag_,word.pos_,word.dep_))\n",
        "spacy.explain(\"nsubj\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Sally', 'NNP', 'PROPN', 'nsubj')\n",
            "('likes', 'VBZ', 'VERB', 'ROOT')\n",
            "('sam', 'NNP', 'PROPN', 'dobj')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nominal subject'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-QrXqmRXqrH",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing dependency using displacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqZXAJzvXq0s",
        "colab_type": "code",
        "outputId": "69e185cf-74ba-4f2e-b1f5-7b15d44a6028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "from spacy import displacy\n",
        "displacy.render(exp4,style='dep',jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f1e60b672c414c0da92a0b4c3f8e570a-0\" class=\"displacy\" width=\"575\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Sally</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">likes</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">sam</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f1e60b672c414c0da92a0b4c3f8e570a-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f1e60b672c414c0da92a0b4c3f8e570a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f1e60b672c414c0da92a0b4c3f8e570a-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f1e60b672c414c0da92a0b4c3f8e570a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdgp2EMWxd4c",
        "colab_type": "text"
      },
      "source": [
        "# Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3EwYdwIxeGO",
        "colab_type": "code",
        "outputId": "598867df-ae36-4907-f558-e59e9089607e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "doc=nlp(\"study studying studious studio student\")\n",
        "for word in doc:\n",
        "  print(word.text,word.lemma_,word.pos_)\n",
        "\n",
        "doc2=nlp(\"walking walks walk walker\")\n",
        "for word in doc2:\n",
        "  print(word.text,word.lemma_,word.pos_)\n",
        "\n",
        "doc3=nlp(\"good goods run running runner runny was be were\")\n",
        "for word in doc3:\n",
        "  print(word.text,word.lemma_,word.pos_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "study study VERB\n",
            "studying study VERB\n",
            "studious studious ADJ\n",
            "studio studio NOUN\n",
            "student student NOUN\n",
            "walking walk VERB\n",
            "walks walk VERB\n",
            "walk walk VERB\n",
            "walker walker PROPN\n",
            "good good ADJ\n",
            "goods good NOUN\n",
            "run run VERB\n",
            "running run VERB\n",
            "runner runner NOUN\n",
            "runny runny NOUN\n",
            "was be AUX\n",
            "be be AUX\n",
            "were be AUX\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVzAFbtQ3u-I",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition or Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S-lTGMK3vZW",
        "colab_type": "code",
        "outputId": "b0bdd6f6-0c11-403c-f6d8-0b78ca44edc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "wikitext=nlp(\"By 2020 the telecom company Orange , will relocate from Turkey to Orange Country in the U.S. close to Apple. It will cost them 2 million dollars \")\n",
        "for word in wikitext.ents:\n",
        "  print(word.text,word.label_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020 DATE\n",
            "Orange ORG\n",
            "Turkey GPE\n",
            "Orange Country ORG\n",
            "U.S. GPE\n",
            "Apple ORG\n",
            "2 million dollars MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ1RCQUp8pv1",
        "colab_type": "code",
        "outputId": "7a1222a7-ea10-4cdb-8e0e-1e940f75f591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spacy.explain(\"ORG\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Companies, agencies, institutions, etc.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npiz69XF8_nO",
        "colab_type": "code",
        "outputId": "5bc2f17c-5965-4e43-eb5e-38ed0939f69f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "displacy.render(wikitext,style=\"ent\",jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " the telecom company \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Orange\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " , will relocate from \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Turkey\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " to \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Orange Country\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.S.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " close to \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ". It will cost them \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2 million dollars\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              " </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gF736w_B-li",
        "colab_type": "text"
      },
      "source": [
        "# Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNVnm9xoB-vh",
        "colab_type": "code",
        "outputId": "2b6c4334-bc44-49ef-dfd5-1eee72133ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "print (STOP_WORDS)\n",
        "len(STOP_WORDS)\n",
        "\n",
        "# testing the word if she is a stop word \n",
        "print(nlp.vocab[\"the\"].is_stop)\n",
        "print(nlp.vocab[\"theme\"].is_stop)\n",
        "\n",
        "#Filttering non stop words\n",
        "mysentence=nlp(\"this is a sentence about how to use stopwords in natural language processing\")\n",
        "print(mysentence)\n",
        "for word in mysentence:\n",
        "  if word.is_stop==True:\n",
        "    print (word)\n",
        "#Filttering non stop words\n",
        "for word in mysentence:\n",
        "  if word.is_stop==False:\n",
        "    print (word)\n",
        "\n",
        "[word for word in mysentence if word.is_stop==False] # IN List\n",
        "\n",
        "#Adding stop word\n",
        "#STOP_WORDS.add(\"aaaa\")\n",
        "#print(nlp.vocab[\"aaaa\"].is_stop)\n",
        "\n",
        "#removing stop word\n",
        "#STOP_WORDS.remove(\"aaaa\")\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'same', 'nine', 'all', 'next', 'sometime', 'our', 'somewhere', 'under', 'formerly', 'another', 'give', 'yet', 'onto', 'which', 'a', 'out', 'three', 'towards', 'keep', 'call', 'below', 'seeming', 'still', 'n’t', 'although', 'fifteen', 'through', 'who', 'always', 'namely', 'its', 'wherein', 'himself', 'off', 're', 'various', 'wherever', '‘re', 'whereby', \"'d\", 'several', 'six', 'really', 'ours', 'third', 'whereafter', 'on', 'neither', 'with', 'him', 'they', 'nowhere', 'myself', 'why', 'should', \"n't\", 'many', 'where', 'can', 'first', 'nobody', 'anyone', 'we', 'one', 'from', 'have', 'none', 'would', 'besides', 'hereafter', 'name', 'those', 'may', 'been', 'above', 'most', 'beside', 'four', 'others', 'over', 'everyone', 'as', 'used', 'whole', 'few', 'enough', \"'ll\", \"'ve\", '’ll', 'indeed', 'ca', 'part', 'across', 'amount', 'how', 'the', 'throughout', 'once', 'yourself', 'thereupon', 'were', '‘ve', 'put', 'other', 'does', 'thru', 'them', 'his', 'somehow', 'not', 'then', 'fifty', 'again', 'might', 'my', \"'s\", 'alone', 'done', 'quite', '’m', 'mine', 'because', 'only', 'before', 'two', '‘m', 'meanwhile', 'anyhow', 'has', 'last', 'someone', 'in', 'therein', 'what', 'these', 'too', 'very', 'regarding', 'show', 'was', 'often', 'whose', 'perhaps', 'down', 'become', 'nevertheless', 'forty', 'whom', 'moreover', 'during', 'eleven', 'full', 'get', 'behind', 'latter', 'say', 'do', 'such', 'that', 'thus', 'when', 'you', 'both', 'her', '’ve', 'anywhere', 'everything', 'never', 'hereupon', 'noone', 'front', 'amongst', 'ever', 'along', 'move', 'becoming', 'much', 'is', 'no', 'now', 'per', 'seem', 'any', 'beforehand', 'see', 'herein', 'had', 'to', 'twelve', 'he', 'within', 'about', 'toward', 'there', 'hh', 'five', 'made', 'beyond', 'or', 'though', 'yours', 'mostly', 'hence', 'serious', 'side', 'themselves', 'did', 'afterwards', 'upon', 'otherwise', 'own', 'unless', 'seemed', 'since', 'eight', 'anything', 'here', 'thereby', 'if', 'at', 'nothing', 'hereby', 'make', 'twenty', 'however', 'are', 'into', 'hundred', 'she', 'whatever', 'whence', '‘s', 'than', 'less', 'it', 'go', 'until', 'whenever', 'cannot', 'either', 'me', \"'re\", 'empty', '‘d', 'while', 'ourselves', 'top', '’re', 'herself', 'almost', 'more', 'us', 'becomes', 'rather', 'this', 'hers', 'back', 'sixty', 'without', 'their', 'also', 'up', \"'m\", 'sometimes', 'take', 'am', 'anyway', 'will', 'even', 'between', 'became', 'everywhere', 'whereupon', 'test', 'using', '’s', 'yourselves', 'elsewhere', 'least', 'thence', 'something', 'among', 'be', 'i', 'against', 'doing', 'due', 'an', 'each', 'else', 'after', 'itself', 'whither', 'please', 'your', 'just', 'well', 'being', 'n‘t', 'and', 'further', 'must', 'except', 'latterly', 'could', 'some', 'thereafter', 'for', 'seems', 'around', 'together', 'ten', 'via', 'whoever', '’d', 'therefore', 'so', 'by', 'whereas', '‘ll', 'of', 'bottom', 'whether', 'former', 'but', 'every', 'nor', 'lol', 'already'}\n",
            "True\n",
            "False\n",
            "this is a sentence about how to use stopwords in natural language processing\n",
            "this\n",
            "is\n",
            "a\n",
            "about\n",
            "how\n",
            "to\n",
            "in\n",
            "sentence\n",
            "use\n",
            "stopwords\n",
            "natural\n",
            "language\n",
            "processing\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8F2pl03pBWp",
        "colab_type": "text"
      },
      "source": [
        "# Loading from my google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqnlT6d7pBir",
        "colab_type": "code",
        "outputId": "3beab1fd-2b41-4901-a0d9-539bf901a261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}